---
# Tempo Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo-config
  namespace: observability
data:
  tempo.yaml: |
    server:
      http_listen_port: 3200

    distributor:
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318

    ingester:
      trace_idle_period: 10s
      max_block_bytes: 1000000
      max_block_duration: 5m

    compactor:
      compaction:
        block_retention: 48h

    storage:
      trace:
        backend: local
        local:
          path: /var/tempo/traces
        wal:
          path: /var/tempo/wal
---
# Mimir Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: mimir-config
  namespace: observability
data:
  mimir.yaml: |
    multitenancy_enabled: false

    server:
      http_listen_port: 9009
      grpc_listen_port: 9095

    distributor:
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory

    ingester:
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory
        replication_factor: 1

    blocks_storage:
      backend: filesystem
      bucket_store:
        sync_dir: /data/tsdb-sync
      filesystem:
        dir: /data/blocks
      tsdb:
        dir: /data/tsdb

    compactor:
      data_dir: /data/compactor
      sharding_ring:
        kvstore:
          store: inmemory

    ruler:
      enable_api: true
      evaluation_interval: 1m
      rule_path: /data/mimir/rules-tmp
      alertmanager_url: http://alertmanager:9093/alertmanager

    ruler_storage:
      backend: filesystem
      filesystem:
        dir: /data/mimir/rules

    store_gateway:
      sharding_ring:
        replication_factor: 1

    # IMPORTANT: Set proper limits for ingestion
    # 0 means disabled (not unlimited!)
    limits:
      max_global_series_per_user: 1000000
      ingestion_rate: 100000
      ingestion_burst_size: 200000
---
# Alloy Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: observability
data:
  config.alloy: |
    // OTLP Receiver
    otelcol.receiver.otlp "default" {
      grpc {
        endpoint = "0.0.0.0:4317"
      }
      http {
        endpoint = "0.0.0.0:4318"
      }

      output {
        metrics = [otelcol.processor.batch.default.input]
        logs    = [otelcol.processor.batch.default.input]
        traces  = [otelcol.processor.batch.default.input]
      }
    }

    // Batch Processor
    otelcol.processor.batch "default" {
      output {
        metrics = [otelcol.exporter.prometheus.mimir.input]
        logs    = [otelcol.exporter.loki.default.input]
        traces  = [otelcol.exporter.otlp.tempo.input]
      }
    }

    // Export metrics to Mimir via Prometheus Remote Write
    otelcol.exporter.prometheus "mimir" {
      forward_to = [prometheus.remote_write.mimir.receiver]
    }

    prometheus.remote_write "mimir" {
      endpoint {
        url = "http://mimir.observability.svc.cluster.local:9009/api/v1/push"
      }
    }

    // Export logs to Loki
    otelcol.exporter.loki "default" {
      forward_to = [loki.write.default.receiver]
    }

    loki.write "default" {
      endpoint {
        url = "http://loki.observability.svc.cluster.local:3100/loki/api/v1/push"
      }
    }

    // Export traces to Tempo
    otelcol.exporter.otlp "tempo" {
      client {
        endpoint = "tempo.observability.svc.cluster.local:4317"
        tls {
          insecure = true
        }
      }
    }
---
# Loki Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: observability
data:
  loki.yaml: |
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    common:
      instance_addr: 127.0.0.1
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        kvstore:
          store: inmemory

    query_range:
      results_cache:
        cache:
          embedded_cache:
            enabled: true
            max_size_mb: 100

    schema_config:
      configs:
        - from: 2020-10-24
          store: tsdb
          object_store: filesystem
          schema: v13
          index:
            prefix: index_
            period: 24h

    ruler:
      alertmanager_url: http://alertmanager:9093
      enable_api: true
      storage:
        type: local
        local:
          directory: /loki/rules
      rule_path: /loki/rules-tmp
      evaluation_interval: 1m

    limits_config:
      ingestion_rate_mb: 10
      ingestion_burst_size_mb: 20
      max_streams_per_user: 0
      max_line_size: 256kb
      reject_old_samples: true
      reject_old_samples_max_age: 168h

    storage_config:
      tsdb_shipper:
        active_index_directory: /loki/tsdb-index
        cache_location: /loki/tsdb-cache

    compactor:
      working_directory: /loki/compactor
      retention_enabled: true
      retention_delete_delay: 2h
      delete_request_store: filesystem
---
# Loki Recording Rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-rules
  namespace: observability
data:
  contextcore-rules.yaml: |
    groups:
      - name: contextcore_task_progress
        interval: 1m
        rules:
          - record: "project:contextcore_task_percent_complete:max_over_time5m"
            expr: |
              max by (project_id, task_id, task_type, sprint_id) (
                max_over_time(
                  {service="contextcore"} | json
                  | event = "task.progress_updated"
                  | unwrap percent_complete [5m]
                )
              )
            labels:
              source: loki
          - record: "project_sprint:contextcore_task_percent_complete:avg"
            expr: |
              avg by (project_id, sprint_id) (
                project:contextcore_task_percent_complete:max_over_time5m{sprint_id!=""}
              )
            labels:
              source: derived
          - record: "project_sprint:contextcore_task_completed:count"
            expr: |
              count by (project_id, sprint_id) (
                project:contextcore_task_percent_complete:max_over_time5m == 100
              )
            labels:
              source: derived
          - record: "project_task:contextcore_task_progress:rate1h"
            expr: |
              sum by (project_id, task_id) (
                rate(
                  {service="contextcore"} | json
                  | event = "task.progress_updated"
                  | unwrap percent_complete [1h]
                )
              )
            labels:
              source: loki
      - name: contextcore_task_status
        interval: 1m
        rules:
          - record: "project:contextcore_task_count:count_by_status"
            expr: |
              count by (project_id, to_status) (
                last_over_time(
                  {service="contextcore"} | json
                  | event = "task.status_changed" [5m]
                )
              )
            labels:
              source: loki
  contextcore-alerts.yaml: |
    groups:
      - name: contextcore_alerts
        rules:
          - alert: ContextCoreExporterFailure
            expr: |
              count_over_time(
                {service="contextcore"} | json
                | severity_text = "ERROR"
                | body =~ ".*OTLP.*export.*fail.*|.*exporter.*error.*" [5m]
              ) > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "OTLP exporter failure detected"
              runbook_url: "docs/OPERATIONAL_RUNBOOK.md#otlp-exporter-failure"
          - alert: ContextCoreSpanStateLoss
            expr: |
              count_over_time(
                {service="contextcore"} | json
                | severity_text = "ERROR"
                | body =~ ".*state.*persist.*fail.*|.*span.*state.*lost.*" [5m]
              ) > 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Span state persistence failure"
              runbook_url: "docs/OPERATIONAL_RUNBOOK.md#span-state-loss"
      - name: contextcore_task_alerts
        rules:
          - alert: ContextCoreTaskStalled
            expr: |
              (time() - max by (project_id, task_id) (
                timestamp(count_over_time(
                  {service="contextcore"} | json
                  | event = "task.status_changed" [24h]
                ) > 0)
              )) > 86400
            for: 1h
            labels:
              severity: warning
            annotations:
              summary: "Task {{ $labels.task_id }} stalled > 24h"
              runbook_url: "docs/OPERATIONAL_RUNBOOK.md#task-stalled"
---
# Mimir Recording Rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: mimir-rules
  namespace: observability
data:
  rules.yaml: |
    groups:
      - name: contextcore_mimir_precompute
        interval: 1m
        rules:
          - record: "project_sprint:contextcore_sprint_planned_points:last"
            expr: max by (project_id, sprint_id) (contextcore_sprint_planned_points)
  alerts.yaml: |
    groups:
      - name: contextcore_mimir_alerts
        rules:
          - alert: ContextCoreInsightLatencyHigh
            expr: |
              histogram_quantile(0.99,
                sum(rate(contextcore_insight_query_duration_milliseconds_bucket[5m])) by (le)
              ) > 500
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "Insight query latency > 500ms P99"
              runbook_url: "docs/OPERATIONAL_RUNBOOK.md#insight-latency"
---
# Grafana Datasources
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: observability
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
      - name: Loki
        uid: loki
        type: loki
        access: proxy
        url: http://loki.observability.svc.cluster.local:3100
        isDefault: false
        jsonData:
          maxLines: 1000

      - name: Mimir
        uid: mimir
        type: prometheus
        access: proxy
        url: http://mimir.observability.svc.cluster.local:9009/prometheus
        isDefault: true
        jsonData:
          prometheusType: Mimir

      - name: Tempo
        uid: tempo
        type: tempo
        access: proxy
        url: http://tempo.observability.svc.cluster.local:3200
        isDefault: false
        jsonData:
          tracesToLogsV2:
            datasourceUid: loki
            spanStartTimeShift: '-1h'
            spanEndTimeShift: '1h'
            filterByTraceID: true
            filterBySpanID: true
          tracesToMetrics:
            datasourceUid: mimir
          serviceMap:
            datasourceUid: mimir
          nodeGraph:
            enabled: true
          lokiSearch:
            datasourceUid: loki
---
# Grafana Dashboard Provisioning Config
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards-config
  namespace: observability
data:
  dashboards.yaml: |
    apiVersion: 1
    providers:
      - name: 'contextcore'
        orgId: 1
        folder: 'ContextCore'
        folderUid: 'contextcore'
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/contextcore
